{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting spanish_sentiment_analysis\n",
      "  Downloading spanish_sentiment_analysis-1.0.0-py3-none-any.whl (15.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 15.8 MB 1.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: nltk in /Users/ecrespo/opt/anaconda3/lib/python3.7/site-packages (from spanish_sentiment_analysis) (3.4.5)\n",
      "Requirement already satisfied: scipy in /Users/ecrespo/opt/anaconda3/lib/python3.7/site-packages (from spanish_sentiment_analysis) (1.4.1)\n",
      "Collecting marisa-trie\n",
      "  Downloading marisa-trie-0.7.5.tar.gz (270 kB)\n",
      "\u001b[K     |████████████████████████████████| 270 kB 20.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy in /Users/ecrespo/opt/anaconda3/lib/python3.7/site-packages (from spanish_sentiment_analysis) (1.18.1)\n",
      "Collecting sklearn\n",
      "  Downloading sklearn-0.0.tar.gz (1.1 kB)\n",
      "Requirement already satisfied: six in /Users/ecrespo/opt/anaconda3/lib/python3.7/site-packages (from nltk->spanish_sentiment_analysis) (1.14.0)\n",
      "Requirement already satisfied: scikit-learn in /Users/ecrespo/opt/anaconda3/lib/python3.7/site-packages (from sklearn->spanish_sentiment_analysis) (0.22.1)\n",
      "Requirement already satisfied: joblib>=0.11 in /Users/ecrespo/opt/anaconda3/lib/python3.7/site-packages (from scikit-learn->sklearn->spanish_sentiment_analysis) (0.15.1)\n",
      "Building wheels for collected packages: marisa-trie, sklearn\n",
      "  Building wheel for marisa-trie (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for marisa-trie: filename=marisa_trie-0.7.5-cp37-cp37m-macosx_10_9_x86_64.whl size=178765 sha256=8c14cae731a6393808e55865b33caf7893ea0bb1226bce9c1bd3b66ed3a741b7\n",
      "  Stored in directory: /Users/ecrespo/Library/Caches/pip/wheels/01/ac/46/c838fd1aee138a8fd92ae30b04020995182eb4d99dec1e12ea\n",
      "  Building wheel for sklearn (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sklearn: filename=sklearn-0.0-py2.py3-none-any.whl size=1315 sha256=c91dc1d18c65a626b3db2791b48713549be63095da3336c7367ff55afa96fe74\n",
      "  Stored in directory: /Users/ecrespo/Library/Caches/pip/wheels/46/ef/c3/157e41f5ee1372d1be90b09f74f82b10e391eaacca8f22d33e\n",
      "Successfully built marisa-trie sklearn\n",
      "Installing collected packages: marisa-trie, sklearn, spanish-sentiment-analysis\n",
      "Successfully installed marisa-trie-0.7.5 sklearn-0.0 spanish-sentiment-analysis-1.0.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install spanish_sentiment_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ecrespo/opt/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will download some functions from the nltk package if not found on the computer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/ecrespo/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    }
   ],
   "source": [
    "from classifier import SentimentClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "analizador = SentimentClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'textos' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-b441de246eeb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0manalizador\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtextos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'textos' is not defined"
     ]
    }
   ],
   "source": [
    "analizador.predict(textos[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-84fd6f7fade4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sentimiento'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtextos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manalizador\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m#nueva columna del df de pandas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df['sentimiento']=df.textos.apply(analizador.predict)  #nueva columna del df de pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-7f65ab9e7d84>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sentimiento'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlang\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'en'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df['sentimiento'][df.lang=='en'] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting textblob\n",
      "  Downloading textblob-0.15.3-py2.py3-none-any.whl (636 kB)\n",
      "\u001b[K     |████████████████████████████████| 636 kB 1.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: nltk>=3.1 in /Users/ecrespo/opt/anaconda3/lib/python3.7/site-packages (from textblob) (3.4.5)\n",
      "Requirement already satisfied: six in /Users/ecrespo/opt/anaconda3/lib/python3.7/site-packages (from nltk>=3.1->textblob) (1.14.0)\n",
      "Installing collected packages: textblob\n",
      "Successfully installed textblob-0.15.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting googletrans\n",
      "  Downloading googletrans-2.4.0.tar.gz (17 kB)\n",
      "Requirement already satisfied: requests in /Users/ecrespo/opt/anaconda3/lib/python3.7/site-packages (from googletrans) (2.23.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/ecrespo/opt/anaconda3/lib/python3.7/site-packages (from requests->googletrans) (2.9)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /Users/ecrespo/opt/anaconda3/lib/python3.7/site-packages (from requests->googletrans) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/ecrespo/opt/anaconda3/lib/python3.7/site-packages (from requests->googletrans) (1.25.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/ecrespo/opt/anaconda3/lib/python3.7/site-packages (from requests->googletrans) (2020.4.5.1)\n",
      "Building wheels for collected packages: googletrans\n",
      "  Building wheel for googletrans (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for googletrans: filename=googletrans-2.4.0-py3-none-any.whl size=15774 sha256=73bb4fb370f4fef08b139f3b5d0a9cf0d741c6edda21dd36330fad96e11b9660\n",
      "  Stored in directory: /Users/ecrespo/Library/Caches/pip/wheels/29/2c/06/957b5a801b311507090697dde39473f3d70154f1ca7142efa8\n",
      "Successfully built googletrans\n",
      "Installing collected packages: googletrans\n",
      "Successfully installed googletrans-2.4.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install googletrans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from googletrans import Translator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "translator = Translator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<googletrans.models.Translated at 0x7ffda00fc9d0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translator.translate('hola como teva')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<googletrans.models.Translated at 0x7ffd9befa710>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translator.translate('Hi guy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.2.0-cp37-cp37m-macosx_10_11_x86_64.whl (175.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 175.3 MB 32.9 MB/s eta 0:00:01    |████████                        | 43.6 MB 10.1 MB/s eta 0:00:14     |████████▏                       | 44.8 MB 10.1 MB/s eta 0:00:13     |█████████████████████           | 115.0 MB 3.6 MB/s eta 0:00:17     |████████████████████████████▋   | 157.0 MB 12.3 MB/s eta 0:00:02\n",
      "\u001b[?25hCollecting keras-preprocessing>=1.1.0\n",
      "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "\u001b[K     |████████████████████████████████| 42 kB 1.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scipy==1.4.1; python_version >= \"3\" in /Users/ecrespo/opt/anaconda3/lib/python3.7/site-packages (from tensorflow) (1.4.1)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Downloading opt_einsum-3.2.1-py3-none-any.whl (63 kB)\n",
      "\u001b[K     |████████████████████████████████| 63 kB 6.3 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting tensorflow-estimator<2.3.0,>=2.2.0\n",
      "  Downloading tensorflow_estimator-2.2.0-py2.py3-none-any.whl (454 kB)\n",
      "\u001b[K     |████████████████████████████████| 454 kB 34.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting astunparse==1.6.3\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /Users/ecrespo/opt/anaconda3/lib/python3.7/site-packages (from tensorflow) (0.34.2)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/ecrespo/opt/anaconda3/lib/python3.7/site-packages (from tensorflow) (1.14.0)\n",
      "Collecting tensorboard<2.3.0,>=2.2.0\n",
      "  Downloading tensorboard-2.2.2-py3-none-any.whl (3.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.0 MB 9.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting absl-py>=0.7.0\n",
      "  Downloading absl-py-0.9.0.tar.gz (104 kB)\n",
      "\u001b[K     |████████████████████████████████| 104 kB 6.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: wrapt>=1.11.1 in /Users/ecrespo/opt/anaconda3/lib/python3.7/site-packages (from tensorflow) (1.11.2)\n",
      "Collecting google-pasta>=0.1.8\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "\u001b[K     |████████████████████████████████| 57 kB 6.8 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy<2.0,>=1.16.0 in /Users/ecrespo/opt/anaconda3/lib/python3.7/site-packages (from tensorflow) (1.18.1)\n",
      "Collecting grpcio>=1.8.6\n",
      "  Downloading grpcio-1.29.0-cp37-cp37m-macosx_10_9_x86_64.whl (2.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.8 MB 17.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting protobuf>=3.8.0\n",
      "  Downloading protobuf-3.12.2-cp37-cp37m-macosx_10_9_x86_64.whl (1.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.3 MB 16.1 MB/s eta 0:00:01     |██████                          | 235 kB 16.1 MB/s eta 0:00:01     |███████████████████████████▋    | 1.1 MB 16.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting gast==0.3.3\n",
      "  Downloading gast-0.3.3-py2.py3-none-any.whl (9.7 kB)\n",
      "Processing /Users/ecrespo/Library/Caches/pip/wheels/7c/06/54/bc84598ba1daf8f970247f550b175aaaee85f68b4b0c5ab2c6/termcolor-1.1.0-cp37-none-any.whl\n",
      "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /Users/ecrespo/opt/anaconda3/lib/python3.7/site-packages (from tensorflow) (2.10.0)\n",
      "Collecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.2.2-py3-none-any.whl (88 kB)\n",
      "\u001b[K     |████████████████████████████████| 88 kB 10.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.6.0.post3-py3-none-any.whl (777 kB)\n",
      "\u001b[K     |████████████████████████████████| 777 kB 21.7 MB/s eta 0:00:01     |███████████▉                    | 286 kB 21.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: werkzeug>=0.11.15 in /Users/ecrespo/opt/anaconda3/lib/python3.7/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (1.0.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /Users/ecrespo/opt/anaconda3/lib/python3.7/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (46.4.0.post20200518)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Using cached google_auth_oauthlib-0.4.1-py2.py3-none-any.whl (18 kB)\n",
      "Collecting google-auth<2,>=1.6.3\n",
      "  Downloading google_auth-1.16.0-py2.py3-none-any.whl (90 kB)\n",
      "\u001b[K     |████████████████████████████████| 90 kB 6.2 MB/s eta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: requests<3,>=2.21.0 in /Users/ecrespo/opt/anaconda3/lib/python3.7/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (2.23.0)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /Users/ecrespo/opt/anaconda3/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow) (1.5.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Users/ecrespo/opt/anaconda3/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow) (1.3.0)\n",
      "Collecting cachetools<5.0,>=2.0.0\n",
      "  Downloading cachetools-4.1.0-py3-none-any.whl (10 kB)\n",
      "Collecting rsa<4.1,>=3.1.4\n",
      "  Using cached rsa-4.0-py2.py3-none-any.whl (38 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "\u001b[K     |████████████████████████████████| 155 kB 26.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/ecrespo/opt/anaconda3/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow) (1.25.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/ecrespo/opt/anaconda3/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow) (2020.4.5.1)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/ecrespo/opt/anaconda3/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow) (2.9)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /Users/ecrespo/opt/anaconda3/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow) (3.0.4)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/ecrespo/opt/anaconda3/lib/python3.7/site-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow) (3.1.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/ecrespo/opt/anaconda3/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow) (3.1.0)\n",
      "Collecting pyasn1>=0.1.3\n",
      "  Using cached pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "Building wheels for collected packages: absl-py\n",
      "  Building wheel for absl-py (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for absl-py: filename=absl_py-0.9.0-py3-none-any.whl size=121931 sha256=af1400bc5a1bf33f55a64ef52df0d386d8a58aa48a22c4b6c03c84e877647ea9\n",
      "  Stored in directory: /Users/ecrespo/Library/Caches/pip/wheels/cc/af/1a/498a24d0730ef484019e007bb9e8cef3ac00311a672c049a3e\n",
      "Successfully built absl-py\n",
      "Installing collected packages: keras-preprocessing, opt-einsum, tensorflow-estimator, astunparse, protobuf, absl-py, markdown, tensorboard-plugin-wit, cachetools, pyasn1, rsa, pyasn1-modules, google-auth, google-auth-oauthlib, grpcio, tensorboard, google-pasta, gast, termcolor, tensorflow\n",
      "Successfully installed absl-py-0.9.0 astunparse-1.6.3 cachetools-4.1.0 gast-0.3.3 google-auth-1.16.0 google-auth-oauthlib-0.4.1 google-pasta-0.2.0 grpcio-1.29.0 keras-preprocessing-1.1.2 markdown-3.2.2 opt-einsum-3.2.1 protobuf-3.12.2 pyasn1-0.4.8 pyasn1-modules-0.2.8 rsa-4.0 tensorboard-2.2.2 tensorboard-plugin-wit-1.6.0.post3 tensorflow-2.2.0 tensorflow-estimator-2.2.0 termcolor-1.1.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: [('n02504458', 'African_elephant', 0.71693057), ('n01871265', 'tusker', 0.25637653), ('n02504013', 'Indian_elephant', 0.025451303)]\n"
     ]
    }
   ],
   "source": [
    "#modelos preentrenados de alto nivel para análisis de imagenes en RRSS\n",
    "#esto sirve para identificar imagenes y es super fácil\n",
    "#ver https://keras.io/api/applications/\n",
    "\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "import numpy as np\n",
    "\n",
    "model = ResNet50(weights='imagenet')\n",
    "\n",
    "img_path = 'elephant.jpg'\n",
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = preprocess_input(x)\n",
    "\n",
    "preds = model.predict(x)\n",
    "# decode the results into a list of tuples (class, description, probability)\n",
    "# (one such list for each sample in the batch)\n",
    "print('Predicted:', decode_predictions(preds, top=3)[0])\n",
    "# Predicted: [(u'n02504013', u'Indian_elephant', 0.82658225), (u'n01871265', u'tusker', 0.1122357), (u'n02504458', u'African_elephant', 0.061040461)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: [('n03032252', 'cinema', 0.13207826), ('n02859443', 'boathouse', 0.12599391), ('n04493381', 'tub', 0.10695911)]\n"
     ]
    }
   ],
   "source": [
    "img_path = 'casa.jpg'\n",
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = preprocess_input(x)\n",
    "\n",
    "preds = model.predict(x)\n",
    "print('Predicted:', decode_predictions(preds, top=3)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
